{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pyntcloud import PyntCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply(file_name):\n",
    "    cloud = PyntCloud.from_file(file_name)\n",
    "    return cloud.points.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(file_name):\n",
    "    vertices = []\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            if line[:2] == 'v ':\n",
    "                index1 = line.find(' ') + 1\n",
    "                index2 = line.find(' ', index1 + 1)\n",
    "                index3 = line.find(' ', index2 + 1)\n",
    "\n",
    "                vertex = (float(line[index1:index2]), float(line[index2:index3]), float(line[index3:-1]))\n",
    "                vertex = [round(vertex[0], 2), round(vertex[1], 2), round(vertex[2], 2)]\n",
    "                vertices.append(np.array(vertex))\n",
    "                \n",
    "    return np.array(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_off(file_name):\n",
    "    vertices = []\n",
    "    with open(file_name) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            vals = line.split(' ')\n",
    "            if i > 2 and len(vals) == 3:\n",
    "                vertex = [float(vals[0]), float(vals[1]), float(vals[2])]\n",
    "                vertices.append(np.array(vertex))\n",
    "\n",
    "    return np.random.permutation(np.array(vertices))[:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 2048, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_clouds = []\n",
    "for i, file_name in enumerate(glob.glob('./data/04379243/*.ply')):\n",
    "    \n",
    "    points = load_ply(file_name)\n",
    "    point_clouds.append(points)\n",
    "    if i == 20:\n",
    "        break\n",
    "        \n",
    "point_clouds = np.array(point_clouds, dtype='float64')\n",
    "\n",
    "point_clouds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (conv1): Conv1d(2048, 256, kernel_size=(1,), stride=(1,))\n",
      "  (conv2): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "  (conv3): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "  (conv4): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
      "  (maxPool1d): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(2048, 256, 1)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 1)\n",
    "        self.conv4 = nn.Conv1d(64, 32, 1)\n",
    "        self.maxPool1d = nn.MaxPool1d(3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxPool1d(x)\n",
    "        return x\n",
    "\n",
    "encoder = Encoder()\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (fc1): Linear(in_features=32, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=6144, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 2048*3)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = x.view(-1, 2048, 3)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "decoder = Decoder()\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda2\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [10/300], loss:297.9619\n",
      "epoch [20/300], loss:211.0951\n",
      "epoch [30/300], loss:167.4910\n",
      "epoch [40/300], loss:133.8176\n",
      "epoch [50/300], loss:106.6925\n",
      "epoch [60/300], loss:86.7010\n",
      "epoch [70/300], loss:70.3970\n",
      "epoch [80/300], loss:59.0366\n",
      "epoch [90/300], loss:50.9145\n",
      "epoch [100/300], loss:44.7963\n",
      "epoch [110/300], loss:40.0339\n",
      "epoch [120/300], loss:35.8852\n",
      "epoch [130/300], loss:32.5109\n",
      "epoch [140/300], loss:29.0754\n",
      "epoch [150/300], loss:26.1767\n",
      "epoch [160/300], loss:24.0825\n",
      "epoch [170/300], loss:22.5180\n",
      "epoch [180/300], loss:20.6729\n",
      "epoch [190/300], loss:19.2295\n",
      "epoch [200/300], loss:18.1551\n",
      "epoch [210/300], loss:17.4493\n",
      "epoch [220/300], loss:17.0104\n",
      "epoch [230/300], loss:16.2729\n",
      "epoch [240/300], loss:15.4895\n",
      "epoch [250/300], loss:15.1692\n",
      "epoch [260/300], loss:15.2019\n",
      "epoch [270/300], loss:14.6596\n",
      "epoch [280/300], loss:13.8604\n",
      "epoch [290/300], loss:13.9948\n",
      "epoch [300/300], loss:13.8393\n"
     ]
    }
   ],
   "source": [
    "from lib.chamfer import ChamferLoss\n",
    "\n",
    "model = AutoEncoder()\n",
    "\n",
    "criterion = ChamferLoss()\n",
    "\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "train_input = torch.from_numpy(point_clouds).float()\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    model = model.cuda()\n",
    "    train_input = train_input.cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_output = model(train_input)\n",
    "    loss = criterion(train_output, train_input)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './models/encoder.pt')\n",
    "torch.save(decoder.state_dict(), './models/decoder.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### switch into cpu mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available :\n",
    "    train_input  = train_input.cpu()  \n",
    "    train_output = train_output.cpu()\n",
    "    generator_output = generator_output.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x[:,0,0] += 2\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_encoder = Encoder()\n",
    "g_decoder = Decoder()\n",
    "\n",
    "g_encoder.load_state_dict(torch.load('./models/encoder.pt'))\n",
    "g_decoder.load_state_dict(torch.load('./models/decoder.pt'))\n",
    "\n",
    "generator = Generator(g_encoder, g_decoder)\n",
    "generator_output = generator(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "index = 10\n",
    "\n",
    "data = train_input[index].detach().numpy().T\n",
    "ax.scatter(data[0], data[1], data[2], zdir='z', s=1, c='b', label='ground truth')\n",
    "\n",
    "data = train_output[index].detach().numpy().T\n",
    "ax.scatter(data[0], data[1], data[2], zdir='z', s=1, c='r', label='decoded')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training (generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "index = 10\n",
    "\n",
    "data = train_input[index].detach().numpy().T\n",
    "ax.scatter(data[0], data[1], data[2], zdir='z', s=1, c='b', label='ground truth')\n",
    "\n",
    "data = generator_output[index].detach().numpy().T\n",
    "ax.scatter(data[0], data[1], data[2], zdir='z', s=1, c='r', label='decoded')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "* Create a mesh by marching cubes\n",
    "* Manimulate latent vector or try something else to generate more nice images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10, 2048, 3)\n",
    "print(input.shape)\n",
    "m = nn.Conv1d(2048, 256, 1)\n",
    "output = m(input)\n",
    "print(output.shape)\n",
    "m = nn.Conv1d(256, 128, 1)\n",
    "output = m(output)\n",
    "m = nn.Conv1d(128, 64, 1)\n",
    "output = m(output)\n",
    "print(output.shape)\n",
    "m = nn.Conv1d(64, 32, 1)\n",
    "output = m(output)\n",
    "print(output.shape)\n",
    "m = nn.MaxPool1d(3)\n",
    "output = m(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
